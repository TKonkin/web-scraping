# Web Scraping and NLP with Requests, BeautifulSoup, and spaCy

Complete the tasks in the Python Notebook in this repository.
Make sure to add and push the pkl or text file of your scraped html (this is specified in the notebook)

## Rubric

* (Question 1) Article html stored in separate file that is committed and pushed: 1 pt
* (Question 2) Article text is correct: 1 pt
* (Question 3) Correct (or equivalent in the case of multiple tokens with same frequency) tokens printed: 1 pt
* (Question 4) Correct (or equivalent in the case of multiple lemmas with same frequency) lemmas printed: 1 pt
* (Question 5) Correct scores for first sentence printed: 2 pts (1 / function)
* (Question 6) Histogram shown with appropriate labelling: 1 pt
* (Question 7) Histogram shown with appropriate labelling: 1 pt
* (Question 8) Thoughtful answer provided: 1 pt

1 - Project Initialization Created a new project repo. Cloned the new repository to local machine. Added .gitignore and requirements.txt, pushed to GitHub. Created local Python virtual environment.

2 - Repeatable Workflow Pull the Latest Changes from GitHub. Activate the Project Virtual Environment. Install dependencies. Save & git-add-commit-push.

4 - Create Notebook Create notebook & select kernel. Complete notebook tasks. Create HTML file of notebook.